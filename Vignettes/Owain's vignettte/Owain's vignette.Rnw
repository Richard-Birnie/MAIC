

\documentclass{article}

\usepackage{hyperref}
\usepackage[backend=bibtex, sorting=none]{biblatex}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}

\usepackage[backend=bibtex]{biblatex}

\bibliography{references.bib}

\title{Matched Adjusted Indirect Comparison: Example using Survival Data }

\author{Owain Saunders \\ Bresmed, 84 Queen St, Sheffield, S1 2DW}

\begin{document}

\maketitle
\abstract{

As part of the development of cost effectiveness models for NICE it is often required to compare two interventions where there is a disconnected treatment network or single-arm study. In this scenario, standard analysis methodologies to compare treatments are not applicable \cite{Dias2011}.
Recently, NICE have issued guidance on how to compare treatments using population-adjusted indirect comparisons, in which individual-level data (ILD) in one or more trials are used to adjust for between-trial differences in the distribution of variables that influence outcome \cite{Phillippo2016a}. The methods discussed are the matched-adjusted indirect comparison (MAIC) and the simulated treatment comparison (STC). An example of how to perform such an analysis for binomial data in R is presented in \cite{Phillippo2016b}. This document describes the steps required to perform an MAIC analysis for a disconnected treatment network where the endpoint of interest is time-to-event. All analyses are performed in the R software package. However, this document does not describe the assumptions/rationale that underpin such analyses or how to interpret the results. The interested reader is directed towards the references at the back of the document; specifically \cite{Phillippo2016a},  \cite{Phillippo2016b} and \cite{Signorovitch2012}.

}
\newpage{}
\section{Introduction}

Bristol-Myers Squibb (BMS) is currently developing nivolumab (Opdivo) for the treatment of advanced hepatocellular cancer (HCC).
The evidence used to inform nivolumab efficacy estimates have been taken from the ILD of the expansion (EXP) phase from the March 2017 database lock  of the CheckMate 040 study \cite{ElKhoueiry2017}. CheckMate 040 was an open-label, non-comparative, phase 1/2 dose escalation and expansion trial.

For the submission of Nivolumab to NICE it was required to compare overall Survival (OS) and progression free survival (PFS) of Nivolumab to Regorafenib. However, a comparison was not available from a randomised trial. As such, efficacy data from the CheckMate 040 study was compared directly to the Regorafenib arm of the RESORCE trial \cite{Bruix2017}; a randomised, double-blind, parallel-group, phase 3 trial where adults with HCC were randomly assigned (2:1) to best supportive care plus oral regorafenib 160 mg or placebo once daily during weeks 1-3 of each 4-week cycle.

However due to the lack of randomisation there was a difference in some of the key prognostic factors that were expected to influence outcome between the two treatments.  In order to adjust for between-trial differences in the distribution of these variables an MAIC analysis was undertaken.

This document describes how such an analysis can be undertaken in R \cite{Rref1} for the endpoint of OS. The code included in this document uses the following R packages: \texttt{haven}, \texttt{survival}, \texttt{survminer}, \texttt{plyr}, \texttt{dplyr}, \texttt{reshape2} and
\texttt{flexsurv}.

\section{Naive Comparison}

Figure \ref{fig:plot1} presents the Kaplan-Meier of OS for nivolumab compared to Regorafenib without adjustment for any imbalances in potentially prognostic or predictive factors; a so called "naive" comparison.

Patient level data were not available for RESORCE. As such, the Kaplan-Meier graph of the regorafenib arm was digitised using the methodology of Guyot et al\cite{Guyot2012}. ILD were avilable for nivolumab from the CheckMate 040 study.

<<echo=-(1:14) >>=
BresMed.blue = rgb(69, 185, 209, max=255)
BresMed.red = rgb(225, 55, 60, max=255)
BresMed.yellow = rgb(238, 224, 30, max=255)
BresMed.pink = rgb(211,78,147,max=255)
BresMed.Dblue=rgb(0,45,92,max=255)
BresMed.Dyellow = rgb(214, 200, 16, max=255)

library(haven, warn.conflicts = FALSE, quietly=TRUE) # loading required libraries
library(survival, warn.conflicts = FALSE, quietly=TRUE)
library(survminer, warn.conflicts = FALSE, quietly=TRUE)
library(plyr, warn.conflicts = FALSE, quietly=TRUE)
library(dplyr, warn.conflicts = FALSE, quietly=TRUE)
library(reshape2, warn.conflicts = FALSE, quietly=TRUE)
library(flexsurv, warn.conflicts = FALSE, quietly=TRUE)

adset <- read_sas(paste("G:/Clients/BresMed (internal)/",
"1839 - Understanding and application of TSD 18",
" (population-adjusted indirect treatment comparisons)",
"/Project/Data for Example/adset.sas7bdat",sep="")) #  CheckMate 040 data

res_reg <- read.csv(paste("G:/Clients/BresMed (internal)/",
"1839 - Understanding and application of TSD 18",
" (population-adjusted indirect treatment comparisons)",
"/Project/Data for Example/RESORCE regorafenib data.csv",sep=""))
# Digitised data from RESORCE trial.

head(res_reg)
# Note, this is digitised data. As such, there is no numerical
# correspondance between OS and PFS records for each row of the data.

KM.nivo <- survfit(Surv(OS,CENOS==0) ~ 1, data = adset,type = "kaplan-meier")
# Survival object for nivolumab
KM.reg <- survfit(Surv(OS,CENOS==0) ~ 1, data = res_reg,type = "kaplan-meier")
# Survival object for regorafenib.

fit <- list(Nivolumab = KM.nivo,Regorafenib = KM.reg)
# list object of Survival objects suitable for ggsurvplot.

BresMed.blue = rgb(69, 185, 209, max=255) # rgb colour definitions.
BresMed.red = rgb(225, 55, 60, max=255)

KM.reg.nivo <- ggsurvplot(fit, combine = TRUE, legend.title = "Treatment",
                          palette=c(BresMed.blue,BresMed.red),
break.time.by = 5,legend.labs = c("Nivolumab","Regorafenib"),risk.table = TRUE)

@

<<echo=-(1:4) >>=

adset$arm <- adset$TRT01P
Combined.data <- rbind.data.frame(adset[,c("OS","CENOS","arm")],
                                  res_reg[,c("OS","CENOS","arm")])
Combined.data$arm_numeric <- ifelse(Combined.data$arm == "NIVOLUMAB 3 mg/kg",1,0)

@

Figure \ref{fig:plot1} presents an unadjusted the Kaplan-Meier plot of OS for nivolumab (CheckMate 040) and regorafenib (RESORCE). The unadjusted HR is \Sexpr{sprintf(" %.2f ",summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))$conf.int[1])} (95\% CI:  \Sexpr{sprintf("%.2f",summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))$conf.int[3])}    \Sexpr{sprintf("%.2f",summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))$conf.int[4])}).

\begin{figure}

\caption{\label{fig:plot1} Kaplan-Meier plot of OS for nivolumab (CheckMate 040) and regorafenib (RESORCE)}

<<echo=-(1:4)>>=
  ## define global chunk options if you will use them often:
# opts_chunk$set(fig.pos = 'H', message = FALSE,
#               cache = TRUE, warning = FALSE,
#               fig.align='center', comment ="")

KM.reg.nivo

@

\end{figure}

\newpage{}
<<>>= echo=-(1:3)

adset$arm <- adset$TRT01P
#  Combine data from both arms into one data frame
Combined.data <- rbind.data.frame(adset[,c("OS","CENOS","arm")],
                                  res_reg[,c("OS","CENOS","arm")])

Combined.data$arm_numeric <- ifelse(Combined.data$arm == "NIVOLUMAB 3 mg/kg",1,0)

summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))
# Fit Cox model with treatment arm as a covariate
@

\section{Prognostic/Predictive factors}

Below is presented a selection of potentially prognostic and/or predictive baseline factors derived using the ILD from the nivolumab arm of the CheckMate 040 study.

<<>>=

CheckMate_040_Baseline <-as.data.frame(adset  %>% summarise(n(), mean(AAGE), sd(AAGE),
`n(male)`= sum(ASEX=="MALE"),
`%(male)`= mean(ASEX=="MALE"),
`n(Hep. B)`= sum(HepB_B==1),`%(Hep. B)`= 100*mean(HepB_B==1),
`n(Hep. C)`= sum(HepC_B==1),`%(Hep. C)`= 100*mean(HepC_B==1),
`n(Non-Asian)`= sum(REGION_B==1),`%(Non-Asian)`= 100*mean(REGION_B==1),
`n(ECOG 1-2)`= sum(ECOG_B==1),`%(ECOG 1-2)`= 100*mean(ECOG_B==1)) )

t(CheckMate_040_Baseline) # Summary of CheckMate 040 Baseline characteristics.

@

These can be compared with published data (\cite{RegClinTrialsgov},\cite{Gregory2017}) available from the regorafenib arm of the RESORCE trial:

\begin{itemize}
\item mean age 64 years (SD =12.4).
\item 88 \% of patients were male.
\item 38 \% had Hepatit B.
\item 21 \% Hepatitis C.
\item 38 \% were non-asian.
\item 35\% had ECOG score of 1-2.
\end{itemize}

These data have been inputted into R via a CSV file to facilitate their use in the statistical estimation described in the section below.

<<>>=
RESORCE_Regorafenib_Baseline <- read.csv(paste("G:/Clients/BresMed (internal)/",
"1839 - Understanding and application of TSD 18",
" (population-adjusted indirect treatment comparisons)/",
"Project/Data for Example/RESORCE_Regorafenib_Baseline.csv",sep=""),header = TRUE)

t(RESORCE_Regorafenib_Baseline)


@

\section{Estimation of Weights}

\subsection{Statistical theory}

As described by Signorovitch et al (\cite{Signorovitch2012}; supplemental appendix), we must find a $\beta$, such that re-weighting baseline characteristics, $x_{i,ild}$, by $\hat{\omega}_i = \exp{(x_{i,ild}.\beta)} $, exactly matches the mean baseline characteristics for the data source for which only aggregate data is available. That is, we must find a solution to:
$$ \bar{x}_{agg}\sum_{i=1}^n \exp{(x_{i,ild}.\beta)}  = \sum_{i=1}^n x_{i,ild}.\exp{(x_{i,ild}.\beta)}\qquad    (1)  $$
This estimator is equivalent to solving the equation
$$ 0 = \sum_{i=1}^n (x_{i,ild} -  \bar{x}_{agg} ).\exp{(x_{i,ild}.\beta)}$$
without loss of generality, it can be assumed that  $\bar{x}_{agg} = 0$ (e.g we could transform baseline characteristics in both trials by substracting  $\bar{x}_{agg})$ leaving the estimator
$$0 = \sum_{i=1}^n (x_{i,ild})\exp{(x_{i,ild}.\beta)}.$$
The right hand side of this estimator is the first derivative of
$$ Q(\beta) = \sum_{i=1}^n  \exp{(x_{i,ild}.\beta)} $$
As described by Signorovitch et al (\cite{Signorovitch2012}; supplemental appendix), $Q(\beta)$ is convex and therefore any finite solution to (1) is unique and corresponds to the global minimum of $Q(\beta)$.

\subsection{Centering of baseline characteristics}

As described above, in order to facilitate estimation of patient weights, $\hat{\omega}_i $, it is necessary to center the baseline characteristics of the CheckMate 040 data using the mean baseline characteristics from the RESORCE trial.

Note, as described by Phillippo (\cite{Phillippo2016a}), it is necessary to balance on both mean and standard deviation for continous variables. This is acheived by centering \texttt{AAGE$^2$} from the nivolumab arm of CheckMate 040 by \texttt{mean.AAGE.$^2$ + age.sd$^2$} from the regorafenib arm of RESORCE trial.

<<>>=

adset$SEX_CHAR <- ifelse(adset$ASEX == "MALE",1,0) # Codeing Sex as 0/1.

# center bsl characteristics of 040 using RESOURCE bsl characteristics

X.ILD <- sweep(with(adset,
cbind(AAGE,AAGE^2,SEX_CHAR,HepB_B,HepC_B,REGION_B,ECOG_B,OS,CENOS)),
               2,with(RESORCE_Regorafenib_Baseline,
cbind(mean.AAGE.,mean.AAGE.^2 +sd.AAGE.^2,X..male.,X..Hep..B.,X..Hep..C.,
                            X..Non.Asian.,X..ECOG.1.2.,0,0)),'-')

head(X.ILD)

@

\subsection{Optimisation procedure}

Following centering of the baseline characteristic of the CheckMate 040 data using the baseline characteristics from the RESORCE trial, the optimisation procedure can be performed to minimise $ Q(\beta) = \sum_{i=1}^n  \exp{(x_{i,ild}.\beta)} $ using the functions provided by Phillippo, \cite{Phillippo2016b}.

<<>>=

objfn <- function(a1, X){
  sum(exp(X %*% a1))
}   # This is a fuction for Q(b) defined above.

# Gradient function => Derivative of Q(b).
gradfn <- function(a1, X){
  colSums(sweep(X, 1, exp(X %*% a1), "*"))
}

## The following is the in built R function used to optimise Q(b) ##
## using Newton-Raphson techniques ##
print(opt1 <- optim(par = rep(0,dim(X.ILD[,!c(colnames(X.ILD) %in%
                                          c("OS","CENOS"))])[2]) ,
fn = objfn, gr = gradfn, X = X.ILD[,!c(colnames(X.ILD) %in% c("OS","CENOS"))],
method = "BFGS"))
a1 <- opt1$par

wt <- as.vector(exp(X.ILD[,!c(colnames(X.ILD) %in% c("OS","CENOS"))] %*% a1))
# Calculation of weights.

head(wt)

wt.rs <- (wt / sum(wt)) * dim(X.ILD)[1] # rescaled weights

@
\section{Weight diagnostics}

Following the calculation of weights, it is necessary to determine whether the optimisation procedure has worked correctly and whether the weights derived are sensible.

\subsection{Has the optimisation worked?}

The first step is to check whether the re-weighted baseline characteristics from the nivolumab arm of CheckMate 040 study match those of the regorafenib arm of the RESORCE trial.

<<>>=

Reweighted.CheckMate_040_Baseline <- as.data.frame(cbind.data.frame(adset,wt) %>%
summarise(n(), age.mean = weighted.mean(AAGE,wt),
          age.sd = sqrt(sum(wt / sum(wt) * (AAGE - age.mean)^2)),
`n(male)`= sum(ASEX=="MALE"),
`%(male)`= weighted.mean(ASEX=="MALE",wt),
`n(Hep. B)`= sum(HepB_B==1),`%(Hep. B)`= 100*weighted.mean(HepB_B==1,wt),
`n(Hep. C)`= sum(HepC_B==1),`%(Hep. C)`= 100*weighted.mean(HepC_B==1,wt),
`n(Non-Asian)`= sum(REGION_B==1),`%(Non-Asian)`= 100*weighted.mean(REGION_B==1,wt),
`n(ECOG 1-2)`= sum(ECOG_B==1),`%(ECOG 1-2)`= 100*weighted.mean(ECOG_B==1,wt)) )

t(Reweighted.CheckMate_040_Baseline) # Re-weighted CheckMate 040 Baseline
#characteristics match those of the regorafenib arm of the RESORCE trial.

@

\subsection{Re-scaled weights}

It is easier to examine the distribution of the weights by scaling them, so that the rescaled weights are relative to the original unit weights of each individual; in other words, a rescaled weight $>$ 1 means that an individual carries more weight in the re-weighted population than the original data. The rescaled weight are calculated as. Further details on interpretation can be found in \cite{Phillippo2016b}.

$$\tilde{\omega}_i  =  \frac{  \hat{\omega}_i}{ \sum_{i=1}^n \hat{\omega}_i }.N $$

<<>>=
wt.rs <- (wt / sum(wt)) * dim(X.ILD)[1] # re-scaled weights.
@

Figure \ref{fig:plot2} presents a Histogram of re-scaled Weights,

\begin{figure}

\caption{\label{fig:plot2} Histogram of re-scaled Weights}

<<>>=
hist(wt.rs,main = "",xlab = "Re-scaled Weights")
@

\end{figure}

\subsection{Effective sample size}

The approximate effective sample size is calculated as

$$  \frac{({ \sum_{i=1}^n \hat{\omega}_i })^2}{ \sum_{i=1}^n \hat{\omega^2}_i  } $$

<<>>=
ESS <- sum(wt)^2/sum(wt^2)
ESS
@

When the ESS is markedly reduced, or equivalently the weights are highly variable, estimates become unstable and inferences depend heavily on just a small number of individuals (\cite{Phillippo2016a},\cite{Phillippo2016b}).

\section{Statistical Analysis}
\subsection{Weighted Kaplan-Meier}

Using the weights derived above, it is possible to create a weighted Kaplan-Meier of the nivolumab arm of CheckMate 040 using the \texttt{weights} statement in \texttt{survfit}. Figure \ref{fig:plot3} presents a combined Kaplan-Meier graph of OS for nivolumab (original), nivolumab (re-weighted) and regorafenib.

Note, the originally derived weights have been passed to \texttt{survfit} rather than the rescaled weights; use of the rescaled weights would artifically increase the sample size. Irrespective of the weights used, the point estimate of the median would remain the same and only the standard error (confidence interval) would change. However, the standard errors derived using both the original and re-scaled weights are incorrect; they do not account for the within-subject correlation in outcomes induced by the use of synthetic weights. This is adressed below.

<<>>=

KM.nivo.weighted <- survfit(Surv(OS, CENOS==0)~1, data = adset,
                            type = "kaplan-meier",weights = wt )
KM.nivo.weighted

# Survival object for nivolumab

fit <- list(Nivolumab = KM.nivo, Nivolumab.weighted = KM.nivo.weighted,
            Regorafenib = KM.reg)
# list object of Survival objects suitable for ggsurvplot.

KM.reg.nivo.weighted <- ggsurvplot(fit, combine = TRUE,legend.title = "Treatment",
                                   palette = c(BresMed.blue,BresMed.pink,BresMed.red),
break.time.by = 5,legend.labs = c("Nivolumab","Nivolumab Re-weighted","Regorafenib"),
risk.table = TRUE)
@

\begin{figure}
\caption{\label{fig:plot3} Kaplan-Meier plot of OS for nivolumab (CheckMate 040), original and re-weighted, and regorafenib (RESORCE)}

<<>>=
KM.reg.nivo.weighted
@

\end{figure}
\newpage{}

\subsection{Incorporation of weights in statistical analysis}

Using the weights derived above, a weighted survival analysis can be performed using the R procedure \texttt{coxph} via the use of \texttt{weights} statement. Note, for the arm which is left unadjusted, regorafenib in this example, it is necessary to assign a weight of one for each patient.
<<echo=-(1:11)>>=
## Mergeing on weights to the adset dataframe.
adset.with.weights <- cbind.data.frame(adset[,c("OS","CENOS","TRT01P")],wt,wt.rs)
names(adset.with.weights) <- c("OS","CENOS","arm","weights","scaled.weights")

## Mergeing on Weights to the regorafenib (RESORCE) dataframe.
res_reg.with.weights <- cbind.data.frame(res_reg[,c("OS","CENOS","arm")],1,1)
names(res_reg.with.weights) <- c("OS","CENOS","arm","weights","scaled.weights")

Combined.data.weights <- rbind.data.frame(adset.with.weights,res_reg.with.weights)
Combined.data.weights$arm_numeric <- ifelse(Combined.data.weights$arm == "NIVOLUMAB 3 mg/kg",
                                    1,0)
@
The weighted HR [95\% CI] is \Sexpr{sprintf("%.2f (%.2f, %.2f)",summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data.weights,weights = weights))$conf.int[1],summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data.weights,weights = weights))$conf.int[3], summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data.weights,weights = weights))$conf.int[4])}. This is of larger magnitude to that of the original (unadjusted HR) \Sexpr{sprintf("%.2f (%.2f, %.2f)",summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))$conf.int[1],summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))$conf.int[3], summary(coxph(Surv(OS,CENOS==0) ~ arm_numeric ,data = Combined.data))$conf.int[4])}. Again, the standard error used to create the confidence interval is incorrect, it does not account for the within-subject correlation in outcomes induced by the use of synthetic weights.

<<>>=
## Mergeing on weights to the adset dataframe.
adset.with.weights <- cbind.data.frame(adset[,c("OS","CENOS","TRT01P")],wt,wt.rs)
names(adset.with.weights) <- c("OS","CENOS","arm","weights","scaled.weights")

## Mergeing on Weights to the regorafenib (RESORCE) dataframe.
res_reg.with.weights <- cbind.data.frame(res_reg[,c("OS","CENOS","arm")],1,1)
names(res_reg.with.weights) <- c("OS","CENOS","arm","weights","scaled.weights")

Combined.data.weights <- rbind.data.frame(adset.with.weights,res_reg.with.weights)
Combined.data.weights$arm_numeric <- ifelse(Combined.data.weights$arm
                                            == "NIVOLUMAB 3 mg/kg",1,0)
head(Combined.data.weights)

Weighted.cox <- coxph(Surv(OS,CENOS==0) ~ arm_numeric,data = Combined.data.weights,
                      weights = weights)

summary(Weighted.cox)

@

\subsection{Estimation of confidence interval}

The use of weights induces a within-subject correlation in outcomes, as observations can have weights that are unequal to one another (\cite{Austin2016},\cite{Thernau2015}). As such, it is necessary to use a variance estimator to take into account the lack of independence of observations. The two common approaches to this are robust variance estimation and bootstrapping. A simulation study was conducted by Austin et al \cite{Austin2016} to examine the different methods in the context of an inverse probability of treatment weighting (IPTW) survival analysis.  The author concluded that the use of a bootstrap estimator resulted in approximately correct estimates of standard errors and confidence intervals with the correct coverage rate. The other estimators resulted in biased estimates of standard errors and confidence intervals with incorrect coverage rates. The use of a bootstrap type estimator is also intuitively appealing, a robust estimator assumes that the weights are known and not subject to any sampling uncertainty. However, a bootstrap estimator allows for quantification of the uncertainty in the estimation of the weights.

Boostrapping involves 1) Sampling, with replacement, from the patients in the nivolumab arm (a bootstrap sample) 2) Estimating a set of weights for each of these bootstrapped datasets and 3) Estimating a HR using each set of estimated weights. This procedure is repeated multiple times to obtain a distribution of HRs for which the  2.5th and 97.5th percentile is used to generate the limits of a confidence interval.

Below is given code to perform the bootstrapping, the results of which are presented below.

<<>>=

## Bootstrap Hazard Ratios ##
n.sim <- 1000 # Number of Bootstrap Simulations.
HR.Bootstrap <- rep(NA,1000)
HR.Bootstrap.scaled.weights <- rep(NA,1000)
Bootstrap.IPD <- lapply(1:5,function(i) matrix(NA,nrow=dim(Combined.data)[1],ncol=6))
# Sets up an array where individual Weights can be stored.

for(i in 1:1000){

set.seed(paste(5432,i,sep=""))  # set seed so results are reproducible.

Bootstrap.ILD <- X.ILD[sample(1:dim(X.ILD)[1],replace =TRUE),]
# Samples patients with replacement.

Bootstrap.Baseline <- Bootstrap.ILD[,!c(colnames(Bootstrap.ILD) %in% c("OS","CENOS"))]

opt1 <- optim(par = rep(0,dim(Bootstrap.Baseline)[2]) , fn = objfn,
              gr = gradfn, X = Bootstrap.Baseline, method = "BFGS")
a1 <- opt1$par

wt <- exp(Bootstrap.Baseline %*% a1)
# Calculation of weights.

wt.rs <- (wt / sum(wt)) * dim(Bootstrap.Baseline)[1] # re-scaled weights.

Bootstrap.ILD.with.weights <- cbind.data.frame(Bootstrap.ILD,wt,wt.rs)
# Merge back on the weights.

Bootstrap.data.frame.with.weights <-
  as.data.frame(Bootstrap.ILD.with.weights[,c("OS","CENOS","wt","wt.rs") ])
names(Bootstrap.data.frame.with.weights) <- c("OS","CENOS","weights","scaled.weights")

Bootstrap.data.frame.with.weights$arm <- "NIVOLUMAB 3 mg/kg"

Bootstrap.combined <- rbind.data.frame(Bootstrap.data.frame.with.weights,
                                       res_reg.with.weights)

Bootstrap.combined$arm_numeric <- ifelse(Bootstrap.combined$arm == "NIVOLUMAB 3 mg/kg",
                                         1,0)

Bootstrap.IPD[[i]] <- Bootstrap.combined

HR.Bootstrap[i] <- as.numeric(exp(coxph(Surv(OS,CENOS==0) ~ arm_numeric,
data = Bootstrap.combined,weights = weights)$coefficients[1]))

HR.Bootstrap.scaled.weights[i] <- as.numeric(exp(coxph(Surv(OS,CENOS==0) ~ arm_numeric,
data = Bootstrap.combined,weights = scaled.weights)$coefficients[1]))
}

@

Figure \ref{fig:plot4} presents a histogram of bootstrapped hazard ratios. It can seen that the distribution of hazard ratios is slightly positively skewed but with no apparent outliers. The median [2.5th, 97.5th] percentile of the distribution of Hazard Ratio is \Sexpr{sprintf("%.2f (%.2f to %.2f)",quantile(HR.Bootstrap,probs = c(0.025,0.5,0.975))[2],quantile(HR.Bootstrap,probs = c(0.025,0.5,0.975))[1],quantile(HR.Bootstrap,probs = c(0.025,0.5,0.975))[3])}. Of note is that this confidence interval is not wider than that taken directly from the Cox proportional hazards model that does not account for the correlation in outcomes induced by the use of synthetic weights.

\begin{figure}
\caption{\label{fig:plot4} Histogram of bootstrapped hazard ratios}

<<>>=echo=-(1:3)>>

hist(HR.Bootstrap,main = "",xlab = "Boostrapped Hazard Ratios (Original Weights)")
abline(v= quantile(HR.Bootstrap,probs = c(0.025,0.5,0.975)), lty=2)

@

\end{figure}
\newpage{}

\section{Extrapolation}

Using the weights deribed in Section 4, it is possible to fit weighted parametric models using the \texttt{flexsurvreg} function in \texttt{flexsurv}.

Figure \ref{fig:plot5} presents a combined Kaplan-Meier graph of OS for nivolumab (original), nivolumab (re-weighted) and regorafenib with superimposed Weibull parametric curve.

<<>>=
Weibull.Nivo <- flexsurvreg(Surv(OS,CENOS==0) ~  1,
data = Combined.data.weights[Combined.data.weights$arm == "NIVOLUMAB 3 mg/kg",],
dist = "Weibull")

Weighted.Weibull.Nivo <- flexsurvreg(Surv(OS,CENOS==0) ~  1,
data = Combined.data.weights[Combined.data.weights$arm == "NIVOLUMAB 3 mg/kg",],
                      weights = weights, dist = "Weibull")

Weibull.Regorafenib <- flexsurvreg(Surv(OS,CENOS==0) ~  1,
data = Combined.data.weights[Combined.data.weights$arm == "Regorafenib (RESORCE)",],
dist = "Weibull")
time_pred <- seq(0,80,1)

## Re-creates the figures above but with an extended time horizon.

KM.reg.nivo.weighted.extrap <- ggsurvplot(fit, combine = TRUE,
                                          legend.title = "Treatment",xlim=c(0,80),
break.time.by = 10,legend.labs = c("Nivolumab","Nivolumab Re-weighted","Regorafenib"),
palette=c(BresMed.blue,BresMed.red,BresMed.pink))

Weibull.Extrapolation <- KM.reg.nivo.weighted.extrap +
geom_smooth(data = as.data.frame(summary(Weibull.Nivo,t= time_pred)),
            aes(y=est,x =time), linetype=1,stat='identity',
            show.legend = FALSE,color=c(BresMed.blue)) +
geom_smooth(data = as.data.frame(summary(Weighted.Weibull.Nivo,t= time_pred)),
            aes(y=est,x =time), linetype=1,stat='identity',
            show.legend = FALSE,color=c(BresMed.red))+
geom_smooth(data = as.data.frame(summary(Weibull.Regorafenib,t= time_pred)),
            aes(y=est,x =time), linetype=1,stat='identity',
            show.legend = FALSE,color=c(BresMed.pink))

@

\begin{figure}
\caption{\label{fig:plot5} Kaplan-Meier plot of OS for nivolumab (CheckMate 040), original and re-weighted, and regorafenib (RESORCE) with Weibull extrapolation}

<<echo=-(1:3)>>=
Weibull.Extrapolation

@
\end{figure}
\newpage{}

\section{Probabilistic sensitivity analysis}

It will also be required to provide uncertainty estimates from the parametric survival model to use within a cost effectiveness model. Using the \texttt{Bootstrap.IPD} dataset above which contains bootstrapped datasets with corresponding weights, it is possible to estimate parametric model parameters for each boostrapped dataset using the code below. These could then be extracted to excel and used within an economic model.

<<>>=

Weibull.parameters <- matrix(NA,nrow=n.sim,ncol=2 )

for(i in 1:1000){

Weibull.parameters[i,] <-coefficients(flexsurvreg(Surv(OS,CENOS==0) ~  1,
data = Bootstrap.IPD[[i]][Bootstrap.IPD[[i]]$arm == "NIVOLUMAB 3 mg/kg",],
weights = weights, dist = "Weibull") )
}

head(Weibull.parameters)
@

\printbibliography

\end{document}





