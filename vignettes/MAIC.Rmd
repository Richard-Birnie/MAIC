---
title: "Matching-Adjusted Indirect Comparison: Example using the MAIC package"
author: "BresMed and Roche"
date: "`r Sys.Date()`"
output: 
  html_vignette:
    number_sections: true
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Matching-Adjusted Indirect Comparison: Example using the MAIC package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


<style type="text/css">

body{ /* Normal  */
      font-size: 14px;
  }
td {  /* Table  */
  font-size: 10px;
}
h1.title {
  font-size: 38px;
}
h1 { /* Header 1 */
  font-size: 28px;
  }
h2 { /* Header 2 */
    font-size: 22px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>



```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 6
)
```

# Introduction

This document describes the steps required to perform an matching-adjusted
indirect comparison (MAIC) analysis using the 'MAIC' package in R for a
disconnected treatment network where the endpoint of interest is either
time-to-event (e.g. overall survival) or binary (e.g. objective tumor
response).

The methods described in this document are based on those originally described by
Signorovitch et al. 2012 and described in the National Institute for Health and
Care Excellence (NICE) Decision Support Unit (DSU) Technical Support Document
(TSD) 18.[@signorovitch2012matching; @Phillippo2016a]

MAIC methods are often required when: 

* There is no common comparator treatment to link a clinical trial of a new
intervention to clinical trials of other treatments in a given disease area. For
example if the only study of a new intervention is a single arm trial with no
control group. This is commonly referred to as an unanchored MAIC.
* A common comparator is available to link a clinical trial of a new
intervention to a clinical trial of one other treatment in a given disease area
but there are substantial differences in patient demographic or disease
characteristics that are believed to be either prognostic or treatment effect
modifiers. This is commonly referred to as an anchored MAIC.

The premise of MAIC methods is to adjust for between-trial differences in
patient demographic or disease characteristics at baseline. When a common
treatment comparator or ‘linked network’ are unavailable, a MAIC assumes that
differences between absolute outcomes that would be observed in each trial are
entirely explained by imbalances in prognostic variables and treatment effect
modifiers. Prognostic variables are those that are predictive of disease
outcomes, independent of the treatment received. For example, older patients may
have increased risk of death compared to younger patients. Treatment effect
modifiers are those variables that influence the relative effect of one
treatment compared to another. For example patients with a better performance
status may experience a larger treatment benefit than those with a worse
performance status. Under this assumption, every prognostic variable and every
treatment effect modifier that is imbalanced between the two studies must be
available. This assumption is generally considered very difficult to
meet.[@Phillippo2016a] There are several ways of identifying prognostic
variables/treatment effect modifiers to be used in the MAIC analyses, some of
which include:

* Clinical expertise (when available to a project)
* Published papers/previous submissions (what has been identified in the disease area previously)
* Exploratory analyses that look at univariable/multivariable analyses (regression models)
* Subgroup analyses of clinical trials may identify interactions between patient
characteristics and the relative treatment effect

## Example Scenario

For the purposes of this example we present an unanchored MAIC of two treatments
in lung cancer with the treatments being compared labelled 'intervention' and
'comparator'. The data used in this example have been simulated to resemble that
'of clinical trial data. The data available are:

* Individual patient data from a single arm study of 'intervention'
* Aggregate summary data for 'comparator'. This could be from a single arm study of
the comparator or from one arm of a randomised controlled trial.

In this example scenario, age, sex, the Eastern Cooperative Oncology Group
performance status (ECOG PS) and smoking status have been identified as
imbalanced prognostic variables/treatment effect modifiers.

# Set up packages, directories and data

## Install packages

The following packages are required to run this example:

```{r, warning = FALSE, message = FALSE}
library(plyr)
library(dplyr)
library(boot)
library(survival)
library(MAIC)
library(ggplot2)
library(survminer)
```


## Read in the data

To perform unanchored MAICs, the following data is required:

* Individual patient data (IPD) from the intervention trial
* Pseudo data for the comparator trial
* Baseline data from the comparator trial

Simulated data for the above is provided with the MAIC package.

### Intervention trial IPD
This example reads in and combines data from three standard simulated data
sets (adsl, adrs and adtte) which are saved as '.csv' files. The data needs some
manipulation to standardize the variable names since the MAIC package functions
assume certain names for some variables

The variables needed for the time to event analyses are:

* Time - a numeric variable
* Event - a binary variable (event=1, censor=0)
* Treatment - a character variable with the name of the intervention treatment 

The variables needed for the binary event analyses are:

* Binary_event - a binary variable (event=1, no event=0)
* Treatment - a character variable with the name of the intervention treatment

For the matching variables:

* All binary variables to be used in the matching should be coded 1 and 0 (see example for sex below).
* The variable names need to be listed in a character vector called <tt>match_cov</tt>.

```{r}
#### Intervention data

# Read in ADaM data and rename variables of interest

adsl <- read.csv(system.file("extdata", "adsl.csv", package = "MAIC", mustWork = TRUE))
adrs <- read.csv(system.file("extdata", "adrs.csv", package = "MAIC", mustWork = TRUE))
adtte <- read.csv(system.file("extdata", "adtte.csv", package = "MAIC", mustWork = TRUE))


adsl <- adsl %>% # Data containing the matching variables
  dplyr::mutate(SEX=ifelse(SEX=="Male", 1, 0)) # Coded 1 for males and 0 for females

adrs <- adrs %>% # Response data
  dplyr::filter(PARAM=="Response") %>%
  dplyr::select(USUBJID, ARM, Binary_event=AVAL) 

adtte <- adtte %>% # Time to event data
  dplyr::filter(PARAMCD=="OS") %>%
  dplyr::mutate(Event=1-CNSR) %>%
  dplyr::select(USUBJID, ARM, Time=AVAL, Event)

# Combine all intervention data
intervention_input <- plyr::join_all(list(adsl, adrs, adtte), type = "full", by=c("USUBJID", "ARM"))
head(intervention_input)

# List out matching covariates
match_cov <- c("AGE",
               "SEX",
               "SMOKE",
               "ECOG0")

```


### Comparator data

Naming of variables in the comparator data should be consistent with those used
in the intervention IPD.

It is common for binary endpoints to be reported as a percentage of responders
with the event and therefore the example code below simulates pseudo-data for a
binary response based on the total number of patients and the proportion of
responders.

The comparator data will include pseudo individual patient data from two
different endpoints and it should be highlighted that there is no 1:1
relationship between endpoints for a given patient since these are reconstructed
data and not actual observed data.
```{r}
#### Comparator pseudo data

# Read in digitised pseudo survival data
comparator_surv <- read.csv(system.file("extdata", "psuedo_IPD.csv", package = "MAIC", mustWork = TRUE))


# Simulate response data based on the known proportion of responders
comparator_n <- nrow(comparator_surv) # total number of patients in the comparator data
comparator_prop_events <- 0.4 # proportion of responders
comparator_binary <- data.frame("Binary_event"=
                                  c(rep(1,comparator_n*comparator_prop_events),
                                    rep(0, comparator_n*(1-comparator_prop_events))))

# Join survival and response comparator data 
# (note the rows do not represent observations from a particular patient)
comparator_input <- cbind(comparator_surv, comparator_binary)


```

### Baseline data from the comparator trial
The aggregate baseline characteristics (number of patients, mean and SD for
continuous variables and proportion for binary variables) from the comparator
trial are needed as a data frame. Naming of the covariates in this data frame
(named below as <tt>target_pop_standard</tt>) should be consistant with the
intervention data (<tt>intervention_input</tt>).

```{r}
# Baseline aggregate data for the comparator population
target_pop <- read.csv(system.file("extdata", "Aggregate data.csv", package = "MAIC", mustWork = TRUE))

# Renames target population cols to be consistent with match_cov
match_cov
names(target_pop)
target_pop_standard <- target_pop %>%
  #EDIT
  dplyr::rename(N=N,
                Treatment="ARM",
                AGE=age.mean,
                SEX=prop.male,
                SMOKE=prop.smoke,
                ECOG0=prop.ecog0
  ) %>%
  dplyr::select(N, Treatment, all_of(match_cov))

```



# Estimate weights

## Statistical theory 

As described by Signorovitch et al. (supplemental appendix), we must find a
$\beta$, such that re-weighting baseline characteristics for the intervention,
$x_{i,ild}$ exactly matches the mean baseline characteristics for the comparator
data source for which only aggregate data is available.

The weights are given by:
$$\hat{\omega}_i=\exp{(x_{i,ild}.\beta)}\qquad (1)$$ That is, we must find a solution to: $$
\bar{x}_{agg}\sum_{i=1}^n \exp{(x_{i,ild}.\beta)}  = \sum_{i=1}^n
x_{i,ild}.\exp{(x_{i,ild}.\beta)}\qquad (2)  $$ This estimator is equivalent to
solving the equation $$ 0 = \sum_{i=1}^n (x_{i,ild} -  \bar{x}_{agg}
).\exp{(x_{i,ild}.\beta)}\qquad (3)$$ without loss of generality, it can be assumed that
$\bar{x}_{agg} = 0$ (e.g we could transform baseline characteristics in both
trials by subtracting  $\bar{x}_{agg}$) leaving the estimator $$0 = \sum_{i=1}^n
(x_{i,ild})\exp{(x_{i,ild}.\beta)}\qquad (4)$$ The right hand side of this estimator is
the first derivative of $$ Q(\beta) = \sum_{i=1}^n  \exp{(x_{i,ild}.\beta)}\qquad (5) $$
As described by Signorovitch et al (supplemental appendix), $Q(\beta)$ is convex
and therefore any finite solution to (2) is unique and corresponds to the global
minimum of $Q(\beta)$.

In order to facilitate estimation of patient weights, $\hat{\omega}_i$, it is
necessary to center the baseline characteristics of the intervention data using
the mean baseline characteristics from the comparator data.

As described by Phillippo, balancing on both mean and standard deviation for
continuous variables (where possible) may be considered in some cases. This is
included in the example below

The code below also specifies an object (<tt>cent_match_cov</tt>) that contains the
names of the centered matching variables - this will be needed for the analyses
below.

```{r}
#### center baseline characteristics
# (subtract the aggregate comparator data from the corresponding column of intervention PLD)
names(intervention_input)
intervention_data <- 
  intervention_input %>%
        dplyr::mutate(Age_centered = AGE - target_pop$age.mean,
                      # matching on both mean and standard deviation for continuous variables:
                      Age_squared_centered = (AGE^2) - (target_pop$age.mean^2 + target_pop$age.sd^2),
                      Sex_centered = SEX - target_pop$prop.male,
                      Smoke_centered = SMOKE - target_pop$prop.smoke,
                      ECOG0_centered = ECOG0 - target_pop$prop.ecog0)
head(intervention_data)

# Set matching covariates
cent_match_cov <- c("Age_centered",
                    "Age_squared_centered",
                    "Sex_centered",
                    "Smoke_centered",
                    "ECOG0_centered")


```


## Optimization procedure

Following the centering of the baseline characteristics of the intervention
study, patient weights can be estimated using the estimate_weights function in
the MAIC package. This performs an optimization procedure to minimize $Q(\beta)
= \sum_{i=1}^n \exp{(x_{i,ild}.\beta)}$ outputs a list containing:

* A character vector containing the names of the matching variables
* An analysis data frame of combined intervention data and comparator data with
weights (patients in the pseudo comparator data are assigned weights of 1)

```{r}
est_weights <- estimate_weights(intervention_data=intervention_data,
                                comparator_data=comparator_input,
                                matching_vars = cent_match_cov)

head(est_weights$analysis_data)

est_weights$matching_vars


```


## Weight diagnostics
Following the calculation of weights, it is necessary to determine whether the
optimization procedure has worked correctly and whether the weights derived are
sensible.

### Are the weights sensible?

#### Effective sample size
For a weighted estimate, the effective sample size (ESS) is the number of
independent non-weighted individuals that would be required to give an estimate
with the same precision as the weighted sample estimate. The approximate
effective sample size is calculated as: $$ ESS =  \frac{({ \sum_{i=1}^n
\hat{\omega}_i })^2}{ \sum_{i=1}^n \hat{\omega^2}_i  } $$ A small ESS, relative
to the original sample size, is an indication that the weights are highly
variable and that the estimate may be unstable. This often occurs if there is
very limited overlap in the distribution of the matching variables between the
populations being compared. If there is insufficient overlap between populations
it may not be possible to obtain reliable estimates of the weights

The MAIC package includes a function to estimate the ESS, as well as produce a
summary of the weights and the profiles of patients with those weights. When
matching on a continuous variable there will be multiple unique weights and the
output 'Weight_profiles' is less useful. When there is a small set of unique
weights 'Weight_profiles' is useful to describe those patients who have more or
less influence on the weighted analyses.

```{r}
# Function to produce a set of diagnostics.
# Calls each of the diagnostic functions above except for plotting histograms
diagnostics <- filter(est_weights$analysis_data, ARM == 'Intervention') %>%
                wt_diagnostics(vars = est_weights$matching_vars)

ESS <- diagnostics$ESS

diagnostics$Summary_of_weights
head(diagnostics$Weight_profiles)


```


#### Rescaled weights

It is easier to examine the distribution of the weights by scaling them, so that
the rescaled weights are relative to the original unit weights of each
individual. In other words, a rescaled weight $>$ 1 means that an individual
carries more weight in the re-weighted population than the original data and a
rescaled weight $<$ 1 means that an individual carries more weight in the
re-weighted population than the original data. The rescaled weights are
calculated as:

$$\tilde{\omega}_i  =  \frac{  \hat{\omega}_i}{ \sum_{i=1}^n \hat{\omega}_i }.N $$

A histogram of the rescaled weights (along with a histogram of the weights) can
be produced using the `hist_wts()` function in the MAIC package.'bin_width'
needs to be adapted depending on the sample size in the data set

```{r}
# Plot histograms of unscaled and rescaled weights
# bin_width needs to be adapted depending on the sample size in the data set
histogram <- est_weights$analysis_data %>% 
              filter(ARM == 'Intervention') %>%
              hist_wts(bin = 50)
histogram

```

### Has the optimization worked?

The following code checks whether the re-weighted baseline characteristics for
the intervention-treated patients match those aggregate characteristics from the
comparator trial and outputs a summary that can be used for reporting.

```{r}
# Create an object to hold the output
baseline_summary <- list('Intervention_weighted' = NA, 'Intervention' = NA, 'Comparator' = NA)

# Summarise matching variables for weighted intervention data
baseline_summary$Intervention_weighted <- est_weights$analysis_data %>% 
  filter(ARM=="Intervention") %>%
  dplyr::select(all_of(match_cov), wt) %>%
  dplyr::summarise_at(match_cov, list(~ weighted.mean(., wt)))

# Summarise matching variables for unweighted intervention data
baseline_summary$Intervention <- est_weights$analysis_data %>% 
  filter(ARM=="Intervention") %>%
  dplyr::select(all_of(match_cov), wt) %>%
  dplyr::summarise_at(match_cov, list(~ mean(.)))

# baseline data for the comparator study
baseline_summary$Comparator <- select(target_pop_standard, match_cov)

# Combine the three summaries
# Takes a list of data frames and binds these together
trt <- names(baseline_summary)
baseline_summary <- dplyr::bind_rows(baseline_summary) %>%
  transmute_all(sprintf, fmt = "%.2f") %>% #apply rounding for presentation
  mutate(ARM = trt) %>% #Add treatment labels
  select(ARM, match_cov)

# Count the number of patients in the unweighted data
summary_n <- est_weights$analysis_data %>%
  dplyr::group_by(ARM) %>%
  dplyr::summarise('N' = n())

# Combine sample sizes with summary data
baseline_summary <- full_join(baseline_summary, summary_n) %>%
  select(ARM, `N/ESS` = N, match_cov)

# Insert the ESS as the sample size for the weighted data
# This is calculated above but can also be obtained using the estimate_ess function as shown below
baseline_summary$`N/ESS`[baseline_summary$ARM == "Intervention_weighted"] <- est_weights$analysis_data %>%
  filter(ARM == 'Intervention') %>%
  estimate_ess(wt_col = 'wt')
baseline_summary

```


# Incorporation of the weights in statistical analysis

## Estimating the relative effect 
Using the weights derived above, relative effects can be estimated using:

* <tt>coxph</tt> for time to event endpoints via the use of the <tt>weights</tt>
statement to estimate a weighted HR from a Cox proportional hazards model
* <tt>glm</tt> for binary endpoints via the use of the <tt>weight</tt> statement
to estimate a weighted OR from logistic regression 

It is important to report the weighted relative effect with the unweighted
relative effect to understand how the weighting has affected the
analysis.

### Bootstrapping a confidence interval
The use of weights induces a within-subject correlation in outcomes, as
observations can have weights that are unequal to one another
[@Austin2016; @Thernau2015]. As such, it is necessary to use a
variance estimator to take into account the lack of independence of
observations. The two common approaches to this are robust variance estimation
and bootstrapping. A simulation study was conducted by Austin et al
\cite{Austin2016} to examine the different methods in the context of an inverse
probability of treatment weighting (IPTW) survival analysis. The author
concluded that the use of a bootstrap estimator resulted in approximately
correct estimates of standard errors and confidence intervals with the correct
coverage rate. The other estimators resulted in biased estimates of standard
errors and confidence intervals with incorrect coverage rates. The use of a
bootstrap type estimator is also intuitively appealing, a robust estimator
assumes that the weights are known and not subject to any sampling uncertainty.
However, a bootstrap estimator allows for quantification of the uncertainty in
the estimation of the weights. 

Bootstrapping involves:

1. Sampling, with replacement, from the patients in the
intervention arm (a bootstrap sample) 
2. Estimating a set of weights for each of
these bootstrapped data sets and 
3. Estimating a hazard ratio (HR)/odds ratio (OR) using each set of estimated
weights. 

This procedure is repeated multiple times to obtain a distribution of HRs/ORs.
For this example, bootstrap estimates of the HRs/ORs were calculated using the
<tt>boot</tt> package. Two different methods for estimating a 95% confidence
interval (CI) from the bootstrap samples were explored:

* Percentile CIs 
    * This method takes the 2.5th and 97.5th percentiles and can be implemented using the <tt>type="norm"</tt> statement in the <tt>boot.ci</tt> function
* Bias-corrected and accelerated (BCa) CIs 
    * This method attempts to correct for any bias and skewness in the distribution of bootstrap estimates and can be implemented using <tt>type="bca"</tt> statement in the <tt>boot.ci</tt> function)

### Example for survival data
In this example, the weighted HR 0.29 (95% CI: 0.21, 0.39) shows a larger difference between treatments
magnitude than the unweighted HR 0.37 (95% CI: 0.30, 0.46). The median of the
bootstrap HR samples is the same as the HR from the weighted Cox model to two
decimel places (HR is 0.29). The bootstrap percentile CI (0.21, 0.36) is
slightly narrower than that of the CI produced from the weighted Cox model
(0.21, 0.39). Finally, it should be noted that results are relatively consistent
across all methods, the intervention treatment significantly reduces the hazard
of death compared with the comparator treatment.
```{r}
## Calculate HRs

# Fit a Cox model without weights to estimate the unweighted HR
unweighted_cox <- coxph(Surv(Time, Event==1) ~ ARM, data = est_weights$analysis_data)

HR_CI_cox <- summary(unweighted_cox)$conf.int %>% 
              as.data.frame() %>%
              dplyr::select(-`exp(-coef)`)
HR_CI_cox

# Fit a Cox model with weights to estimate the weighted HR
weighted_cox <- coxph(Surv(Time, Event==1) ~ ARM, data = est_weights$analysis_data, weights = wt)

HR_CI_cox_wtd <- summary(weighted_cox)$conf.int %>% 
                  as.data.frame() %>%
                  dplyr::select(-`exp(-coef)`)
HR_CI_cox_wtd

## Bootstrapping 

# Separate data into intervention data and comparator data
# The boostrap_HR function below makes use of the estimate_weights fucntion
# which requires separate datasets
int <- filter(est_weights$analysis_data, ARM == 'Intervention')
comp <- filter(est_weights$analysis_data, ARM == 'Comparator')

# Bootstrap 1000 HRs 
HR_bootstraps <- boot(data = int, # intervention data
                      statistic = bootstrap_HR, # bootstrap the HR (defined in the MAIC package)
                      R=1000, # number of bootstrap samples
                      comparator_data = comp, # comparator pseudo data
                      matching = est_weights$matching_vars, # matching variables
                      model = Surv(Time, Event==1) ~ ARM # model to fit
                      )

# Summarize bootstrap estimates in a histogram
# Vertical lines indicate the median and upper and lower CIs
hist(HR_bootstraps$t, main = "", xlab = "Boostrapped HR")
abline(v= quantile(HR_bootstraps$t, probs = c(0.025, 0.5, 0.975)), lty=2)

# Median of the bootstrap samples
HR_median <- median(HR_bootstraps$t)

# Bootstrap CI - Percentile CI
boot_ci_HR <- boot.ci(boot.out = HR_bootstraps, index=1, type="norm") 

# Bootstrap CI - BCa CI
boot_ci_HR_BCA <- boot.ci(boot.out = HR_bootstraps, index=1, type="bca")

## Summary

# Produce a summary of HRs and CIs
HR_summ <-  rbind(HR_CI_cox, HR_CI_cox_wtd) %>% # Unweighted and weights HRs and CIs from Cox models
            dplyr::rename(HR = `exp(coef)`, 
                          HR_low_CI = `lower .95`, 
                          HR_upp_CI = `upper .95`) %>%
            mutate(Method = c("HR (95% CI) from unadjusted Cox model", 
                              "HR (95% CI) from weighted Cox model")) %>%
  
            # Median bootstrapped HR and 95% percentile CI 
            rbind(data.frame("HR" = HR_median, 
                             "HR_low_CI" = boot_ci_HR$normal[2], 
                             "HR_upp_CI" = boot_ci_HR$normal[3], 
                             "Method"="Bootstrap median HR (95% percentile CI)")) %>%
            
            # Median bootstrapped HR and 95% bias-corrected and accelerated bootstrap CI  
            rbind(data.frame("HR" = HR_median, 
                             "HR_low_CI" = boot_ci_HR_BCA$bca[4], 
                             "HR_upp_CI" = boot_ci_HR_BCA$bca[5], 
                             "Method"="Bootstrap median HR (95% BCa CI)")) %>%
            
            # Format HR and CI in one variable, rounded to 3 decimal places
            dplyr::mutate(HR_95_CI = paste0(sprintf('%.3f', HR), 
                                            " (", 
                                            sprintf('%.3f', HR_low_CI), 
                                            ", ", 
                                            sprintf('%.3f', HR_upp_CI), 
                                            ")")
                          ) %>%
            dplyr::select(Method, 'HR (95% CI)' = HR_95_CI)
HR_summ


```

The code below plots the Kaplan-Meier data.

```{r}
# Unweighted intervention data
KM_int <- survfit(formula = Surv(Time, Event==1) ~ 1 , 
                  data = int, 
                  type="kaplan-meier")
# Weighted intervention data
KM_int_wtd <- survfit(formula = Surv(Time, Event==1) ~ 1 , 
                  data = int, 
                  weights = wt,
                  type="kaplan-meier")
# Comparator data
KM_comp <- survfit(formula = Surv(Time, Event==1) ~ 1 , 
                  data = comp, 
                  type="kaplan-meier")

# Combine the survfit objects ready for ggsurvplot
KM_list <- list(Intervention = KM_int, 
                Intervention_weighted = KM_int_wtd, 
                Comparator = KM_comp)

# Produce the Kaplan-Meier plot
KM_plot <- ggsurvplot(KM_list, 
                      combine = TRUE, 
                      risk.table=T, # numbers at risk displayed on the plot
                      break.x.by=50, 
                      xlab="Time (days)", 
                      legend.title = "Treatment",
                      title = "Kaplan-Meier plot of overall survival",
                      legend.labs=c("Intervention", "Intervention weighted", "Comparator"),
                      font.legend = list(size = 10)) +
                      guides(colour=guide_legend(nrow = 2))
KM_plot


```


### Example for response data
In this example, the weighted OR 3.79 (95% CI: 2.56, 5.60) is of smaller
magnitude than the unweighted OR 5.32 (95% CI: 3.89, 7.27) indicating a smaller
difference between treatments. The median of the bootstrap OR samples was
similar to the OR from the weighted logistic regression model to two decimel
places. The median OR from the bootstrap samples was 3.81 compared with the OR
of 3.79 from the weighted logistic regression model. Both the confidence
interval from the bootstrap percentiles is narrower (2.41 to 5.10) than the
interval from the weighted logistic regression model (2.56 to 5.60). Finally, it
should be noted that results are relatively consistent across all methods, the
intervention treatment significantly increases the odds of response compared
with the comparator treatment.
```{r}
## Calculate ORs

# Fit a logistic regression model without weights to estimate the unweighted OR
unweighted_OR <- glm(formula = Binary_event~ARM, 
                     family = binomial(link="logit"), 
                     data = est_weights$analysis_data)

# Log odds ratio
log_OR_CI_logit <- cbind("Log odds ratio" = coef(unweighted_OR), 
                         confint.default(unweighted_OR, level = 0.95))[2,]

# Odds ratio
OR_CI_logit <- exp(cbind("Odds ratio" = coef(unweighted_OR), 
                         confint.default(unweighted_OR, level = 0.95)))[2,]
OR_CI_logit                
  
# Fit a logistic regression model with weights to estimate the weighted OR
weighted_OR <- suppressWarnings(glm(formula = Binary_event~ARM, 
                                    family = binomial(link="logit"), 
                                    data = est_weights$analysis_data, 
                                    weight = wt))

# Weighted log odds ratio
log_OR_CI_logit_wtd <- cbind("Log odds ratio" = coef(weighted_OR), 
                             confint.default(weighted_OR, level = 0.95))[2,]

# Weighted odds ratio
OR_CI_logit_wtd <- exp(cbind("Odds ratio" = coef(weighted_OR), 
                             confint.default(weighted_OR, level = 0.95)))[2,]
OR_CI_logit_wtd


## Bootstrapping

# Separate data into intervention data and comparator data
# The boostrap_OR function below makes use of the estimate_weights fucntion
# which requires separate datasets
int <- filter(est_weights$analysis_data, ARM == 'Intervention')
comp <- filter(est_weights$analysis_data, ARM == 'Comparator')

# Bootstrap 1000 ORs
OR_bootstraps <- boot(data = int, # intervention data
                      statistic = bootstrap_OR, # bootstrap the OR
                      R = 1000, # number of bootstrap samples
                      comparator_data = comp, # comparator pseudo data
                      matching = est_weights$matching_vars, # matching variables
                      model = 'Binary_event ~ ARM' # model to fit
                      )

# Summarize bootstrap estimates in a histogram
# Vertical lines indicate the median and upper and lower CIs
hist(OR_bootstraps$t, main = "", xlab = "Boostrapped OR")
abline(v= quantile(OR_bootstraps$t, probs = c(0.025,0.5,0.975)), lty=2)

# Median of the bootstrap samples
OR_median <- median(OR_bootstraps$t)

# Bootstrap CI - Percentile CI
boot_ci_OR <- boot.ci(boot.out = OR_bootstraps, index=1, type="norm") 

# Bootstrap CI - BCa CI
boot_ci_OR_BCA <- boot.ci(boot.out = OR_bootstraps, index=1, type="bca")


## Summary

# Produce summary of ORs and CIs
OR_summ <-  rbind(OR_CI_logit, OR_CI_logit_wtd) %>% # Unweighted and weighted ORs and CIs from logistic regression models
            as.data.frame() %>%
            dplyr::rename(OR = `Odds ratio`, OR_low_CI = `2.5 %`, OR_upp_CI = `97.5 %`) %>%
            mutate(Method = c("OR (95% CI) from unadjusted logistic regression model", 
                              "OR (95% CI) from weighted logistic regression model")) %>%
  
            # Median bootstrapped HR and 95% percentile CI
            rbind(data.frame("OR" = OR_median, 
                             "OR_low_CI" = boot_ci_OR$normal[2], 
                             "OR_upp_CI" = boot_ci_OR$normal[3], 
                             "Method"="Bootstrap median HR (95% percentile CI)")) %>%
  
            # Median bootstrapped HR and 95% bias-corrected and accelerated bootstrap CI
            rbind(data.frame("OR" = OR_median, 
                             "OR_low_CI" = boot_ci_OR_BCA$bca[4], 
                             "OR_upp_CI" = boot_ci_OR_BCA$bca[5], 
                             "Method"="Bootstrap median HR (95% BCa CI)")) %>%
  
            # Format OR and CI in one variable, rounded to 3 decimal places
            dplyr::mutate(OR_95_CI = paste0(sprintf('%.3f', OR), 
                                            " (", 
                                            sprintf('%.3f', OR_low_CI), 
                                            ", ", 
                                            sprintf('%.3f', OR_upp_CI), 
                                            ")")
                          ) %>%
  
            dplyr::select(Method, OR_95_CI)
OR_summ


```




# References
